{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Experimenting with different models </h1>\n",
    "\n",
    "In this notebook, we try out different ideas.  The first thing we have to do is to create a validation set, so that we are not doing experimentation with our independent test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BUCKET='cloud-training-demos-ml'\n",
    "\n",
    "os.environ['BUCKET'] = BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Read dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindays = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('gs://{}/flights/trainday.csv'.format(BUCKET))\n",
    "traindays.createOrReplaceTempView('traindays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, FloatType, StructType, StructField\n",
    "\n",
    "header = 'FL_DATE,UNIQUE_CARRIER,AIRLINE_ID,CARRIER,FL_NUM,ORIGIN_AIRPORT_ID,ORIGIN_AIRPORT_SEQ_ID,ORIGIN_CITY_MARKET_ID,ORIGIN,DEST_AIRPORT_ID,DEST_AIRPORT_SEQ_ID,DEST_CITY_MARKET_ID,DEST,CRS_DEP_TIME,DEP_TIME,DEP_DELAY,TAXI_OUT,WHEELS_OFF,WHEELS_ON,TAXI_IN,CRS_ARR_TIME,ARR_TIME,ARR_DELAY,CANCELLED,CANCELLATION_CODE,DIVERTED,DISTANCE,DEP_AIRPORT_LAT,DEP_AIRPORT_LON,DEP_AIRPORT_TZOFFSET,ARR_AIRPORT_LAT,ARR_AIRPORT_LON,ARR_AIRPORT_TZOFFSET,EVENT,NOTIFY_TIME'\n",
    "\n",
    "def get_structfield(colname):\n",
    "   if colname in ['ARR_DELAY', 'DEP_DELAY', 'DISTANCE', 'TAXI_OUT']:\n",
    "      return StructField(colname, FloatType(), True)\n",
    "   else:\n",
    "      return StructField(colname, StringType(), True)\n",
    "\n",
    "schema = StructType([get_structfield(colname) for colname in header.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = 'gs://{}/flights/tzcorr/all_flights-00000-*' # 1/30th\n",
    "#inputs = 'gs://{}/flights/tzcorr/all_flights-*'  # FULL\n",
    "flights = spark.read\\\n",
    "            .schema(schema)\\\n",
    "            .csv(inputs.format(BUCKET))\n",
    "\n",
    "# this view can now be queried ...\n",
    "flights.createOrReplaceTempView('flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create separate training and validation data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "SEED = 13\n",
    "traindays = traindays.withColumn(\"holdout\", rand(SEED) > 0.8)  # 80% of data is for training\n",
    "traindays.createOrReplaceTempView('traindays')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(FL_DATE=u'2015-01-01', is_train_day=u'True', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-02', is_train_day=u'False', holdout=True),\n",
       " Row(FL_DATE=u'2015-01-03', is_train_day=u'False', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-04', is_train_day=u'True', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-05', is_train_day=u'True', holdout=True),\n",
       " Row(FL_DATE=u'2015-01-06', is_train_day=u'False', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-07', is_train_day=u'True', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-08', is_train_day=u'True', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-09', is_train_day=u'True', holdout=False),\n",
       " Row(FL_DATE=u'2015-01-10', is_train_day=u'True', holdout=False)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindays.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Logistic regression </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainquery = \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM flights f\n",
    "JOIN traindays t\n",
    "ON f.FL_DATE == t.FL_DATE\n",
    "WHERE\n",
    "  t.is_train_day == 'True' AND\n",
    "  t.holdout == False AND\n",
    "  f.CANCELLED == '0.00' AND \n",
    "  f.DIVERTED == '0.00'\n",
    "\"\"\"\n",
    "traindata = spark.sql(trainquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(FL_DATE=u'2015-02-03', UNIQUE_CARRIER=u'AA', AIRLINE_ID=u'19805', CARRIER=u'AA', FL_NUM=u'1', ORIGIN_AIRPORT_ID=u'12478', ORIGIN_AIRPORT_SEQ_ID=u'1247802', ORIGIN_CITY_MARKET_ID=u'31703', ORIGIN=u'JFK', DEST_AIRPORT_ID=u'12892', DEST_AIRPORT_SEQ_ID=u'1289203', DEST_CITY_MARKET_ID=u'32575', DEST=u'LAX', CRS_DEP_TIME=u'2015-02-03T14:00:00', DEP_TIME=u'2015-02-03T13:56:00', DEP_DELAY=-4.0, TAXI_OUT=24.0, WHEELS_OFF=u'2015-02-03T14:20:00', WHEELS_ON=u'2015-02-03T20:20:00', TAXI_IN=u'7.00', CRS_ARR_TIME=u'2015-02-03T20:35:00', ARR_TIME=u'2015-02-03T20:27:00', ARR_DELAY=-8.0, CANCELLED=u'0.00', CANCELLATION_CODE=None, DIVERTED=u'0.00', DISTANCE=2475.0, DEP_AIRPORT_LAT=u'40.63972222', DEP_AIRPORT_LON=u'-73.77888889', DEP_AIRPORT_TZOFFSET=u'-18000.0', ARR_AIRPORT_LAT=u'33.94250000', ARR_AIRPORT_LON=u'-118.40805556', ARR_AIRPORT_TZOFFSET=u'-28800.0', EVENT=None, NOTIFY_TIME=None, FL_DATE=u'2015-02-03', is_train_day=u'True', holdout=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_example(fields):\n",
    "  return LabeledPoint(\\\n",
    "              float(fields['ARR_DELAY'] < 15), #ontime \\\n",
    "              [ \\\n",
    "                  fields['DEP_DELAY'], # DEP_DELAY \\\n",
    "                  fields['TAXI_OUT'], # TAXI_OUT \\\n",
    "                  fields['DISTANCE'], # DISTANCE \\\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "examples = traindata.rdd.map(to_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.164881634485,-0.133161902516,0.000326021867615] 5.16532271486\n"
     ]
    }
   ],
   "source": [
    "lrmodel = LogisticRegressionWithLBFGS.train(examples, intercept=True)\n",
    "print lrmodel.weights,lrmodel.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lrmodel.setThreshold(0.7) # cancel if prob-of-ontime < 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Evaluate model on the heldout data </h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SELECT\n",
      "  *\n",
      "FROM flights f\n",
      "JOIN traindays t\n",
      "ON f.FL_DATE == t.FL_DATE\n",
      "WHERE\n",
      "  t.is_train_day == 'True' AND\n",
      "  t.holdout == True AND\n",
      "  f.CANCELLED == '0.00' AND \n",
      "  f.DIVERTED == '0.00'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evalquery = trainquery.replace(\"t.holdout == False\",\"t.holdout == True\")\n",
    "print evalquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaldata = spark.sql(evalquery)\n",
    "examples = evaldata.rdd.map(to_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(labelpred):\n",
    "    cancel = labelpred.filter(lambda (label, pred): pred == 0)\n",
    "    nocancel = labelpred.filter(lambda (label, pred): pred == 1)\n",
    "    corr_cancel = cancel.filter(lambda (label, pred): label == pred).count()\n",
    "    corr_nocancel = nocancel.filter(lambda (label, pred): label == pred).count()\n",
    "    \n",
    "    cancel_denom = cancel.count()\n",
    "    nocancel_denom = nocancel.count()\n",
    "    if cancel_denom == 0:\n",
    "        cancel_denom = 1\n",
    "    if nocancel_denom == 0:\n",
    "        nocancel_denom = 1\n",
    "\n",
    "    return {'total_cancel': cancel.count(), \\\n",
    "            'correct_cancel': float(corr_cancel)/cancel_denom, \\\n",
    "            'total_noncancel': nocancel.count(), \\\n",
    "            'correct_noncancel': float(corr_nocancel)/nocancel_denom \\\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'correct_cancel': 0.8430138990490125, 'total_noncancel': 19276, 'correct_noncancel': 0.9511309400290516, 'total_cancel': 6835}\n"
     ]
    }
   ],
   "source": [
    "labelpred = examples.map(lambda p: (p.label, lrmodel.predict(p.features)))\n",
    "print eval(labelpred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
